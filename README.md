# emotion-to-emoji
contains all the necessary files for the project 
PROJECT AIM:
		Our project aims to develop a model which takes the video of a person as an input and displays the emotion using an emoji. This model uses deep learning concepts to recognize the emotion of one or multiple person at a time.
BRIEF WALKTHROUGH:
 LOADING THE APPROPRIATE DATA SET CONTAINING SUFFICIENT IMAGES OF ALL 7 TYPES OF EMOTIONS 
 DATA AUGUMENTATION AND IMAGE PRE-PROCESSING USING “ImageGenerator” and “.flow_from_directory”
 BUILDING THE CNN ARCHITECTURE 
 COMPILING OUR MODEL USING LOSS, OPTIMIZERS (Adam) & METRICS
 TRAINING OUR MODEL WITH TRAINING SET AND SAVING OUR MODEL
 EVALUATING TESTING ACCURACY 
 USING OPENCV WHICH IS A REAL TIME COMPUTER VISION LIBRARY TO CAPTURE THE VIDEO USING APPROPRIATE FRAME 
 MAPPING THE EMOJIS WITH THE HIGHEST PROBABLE EMOTION 
 USING FLASK FRAMEWORK TO BUILD A WEBPAGE  

